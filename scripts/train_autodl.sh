#!/bin/bash
# AutoDL è®­ç»ƒè„šæœ¬
# ä½¿ç”¨æ–¹æ³•: bash scripts/train_autodl.sh [dataset] [config]
# ç¤ºä¾‹: bash scripts/train_autodl.sh mvtec models/cdad_mvtec.yaml

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# é»˜è®¤å‚æ•°
DATASET=${1:-"mvtec"}
CONFIG=${2:-"models/cdad_mvtec.yaml"}
GPUS=${3:-1}
MAX_EPOCHS=${4:-100}
BATCH_SIZE=${5:-32}

echo "ğŸš€ å¼€å§‹åœ¨ AutoDL ä¸Šè®­ç»ƒ Experience Replay æ¨¡å‹"
echo "================================================"
print_info "æ•°æ®é›†: $DATASET"
print_info "é…ç½®æ–‡ä»¶: $CONFIG"
print_info "GPU æ•°é‡: $GPUS"
print_info "æœ€å¤§è½®æ•°: $MAX_EPOCHS"
print_info "æ‰¹æ¬¡å¤§å°: $BATCH_SIZE"
echo "================================================"

# æ£€æŸ¥ç¯å¢ƒ
check_environment() {
    print_info "æ£€æŸ¥è®­ç»ƒç¯å¢ƒ..."
    
    # æ£€æŸ¥ CUDA
    if ! command -v nvidia-smi &> /dev/null; then
        print_error "æœªæ‰¾åˆ° CUDA ç¯å¢ƒ"
        exit 1
    fi
    
    # æ£€æŸ¥ GPU å†…å­˜
    GPU_MEMORY=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    print_info "GPU å†…å­˜: ${GPU_MEMORY}MB"
    
    if [ "$GPU_MEMORY" -lt 8000 ]; then
        print_warning "GPU å†…å­˜è¾ƒå°ï¼Œå»ºè®®å‡å°‘æ‰¹æ¬¡å¤§å°"
        BATCH_SIZE=16
    fi
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    DISK_SPACE=$(df -h . | awk 'NR==2 {print $4}' | sed 's/G//')
    if [ "${DISK_SPACE%.*}" -lt 10 ]; then
        print_warning "ç£ç›˜ç©ºé—´ä¸è¶³ 10GBï¼Œè¯·æ¸…ç†ç©ºé—´"
    fi
    
    print_success "ç¯å¢ƒæ£€æŸ¥å®Œæˆ"
}

# è®¾ç½®ç¯å¢ƒå˜é‡
setup_training_env() {
    print_info "è®¾ç½®è®­ç»ƒç¯å¢ƒå˜é‡..."
    
    export CUDA_VISIBLE_DEVICES=0
    export PYTHONPATH=$PYTHONPATH:$(pwd)
    export TORCH_CUDNN_V8_API_ENABLED=1
    export CUDA_LAUNCH_BLOCKING=0  # å¼‚æ­¥æ‰§è¡Œä»¥æé«˜æ€§èƒ½
    
    # PyTorch ä¼˜åŒ–è®¾ç½®
    export OMP_NUM_THREADS=4
    export MKL_NUM_THREADS=4
    
    print_success "ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ"
}

# åˆ›å»ºè®­ç»ƒç›®å½•
setup_training_dirs() {
    print_info "åˆ›å»ºè®­ç»ƒç›®å½•..."
    
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    EXPERIMENT_NAME="${DATASET}_${TIMESTAMP}"
    
    mkdir -p logs/$EXPERIMENT_NAME
    mkdir -p checkpoints/$EXPERIMENT_NAME
    mkdir -p results/$EXPERIMENT_NAME
    
    export EXPERIMENT_DIR="logs/$EXPERIMENT_NAME"
    export CHECKPOINT_DIR="checkpoints/$EXPERIMENT_NAME"
    export RESULT_DIR="results/$EXPERIMENT_NAME"
    
    print_success "è®­ç»ƒç›®å½•åˆ›å»ºå®Œæˆ: $EXPERIMENT_NAME"
}

# æ£€æŸ¥æ•°æ®é›†
check_dataset() {
    print_info "æ£€æŸ¥æ•°æ®é›†: $DATASET"
    
    case $DATASET in
        "mvtec")
            DATA_DIR="data/MVTec-AD"
            if [ ! -d "$DATA_DIR" ]; then
                print_error "MVTec-AD æ•°æ®é›†æœªæ‰¾åˆ°ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®é›†"
                print_info "ä¸‹è½½å‘½ä»¤: wget https://www.mvtec.com/company/research/datasets/mvtec-ad/downloads/mvtec_anomaly_detection.tar.xz"
                exit 1
            fi
            ;;
        "visa")
            DATA_DIR="data/VisA"
            if [ ! -d "$DATA_DIR" ]; then
                print_error "VisA æ•°æ®é›†æœªæ‰¾åˆ°ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®é›†"
                exit 1
            fi
            ;;
        *)
            print_error "ä¸æ”¯æŒçš„æ•°æ®é›†: $DATASET"
            print_info "æ”¯æŒçš„æ•°æ®é›†: mvtec, visa"
            exit 1
            ;;
    esac
    
    print_success "æ•°æ®é›†æ£€æŸ¥å®Œæˆ: $DATA_DIR"
}

# æ£€æŸ¥é…ç½®æ–‡ä»¶
check_config() {
    print_info "æ£€æŸ¥é…ç½®æ–‡ä»¶: $CONFIG"
    
    if [ ! -f "$CONFIG" ]; then
        print_error "é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: $CONFIG"
        exit 1
    fi
    
    print_success "é…ç½®æ–‡ä»¶æ£€æŸ¥å®Œæˆ"
}

# ä¼˜åŒ–è®­ç»ƒå‚æ•°
optimize_training_params() {
    print_info "ä¼˜åŒ–è®­ç»ƒå‚æ•°..."
    
    # æ ¹æ® GPU å†…å­˜è°ƒæ•´å‚æ•°
    GPU_MEMORY=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    
    if [ "$GPU_MEMORY" -lt 12000 ]; then
        # å°æ˜¾å­˜ä¼˜åŒ–
        export EXPERIENCE_BUFFER_SIZE=3000
        export PROJECTION_DIM=64
        export UPDATE_FREQUENCY=20
        BATCH_SIZE=16
        print_warning "æ£€æµ‹åˆ°å°æ˜¾å­˜ï¼Œä½¿ç”¨ä¼˜åŒ–å‚æ•°"
    elif [ "$GPU_MEMORY" -lt 24000 ]; then
        # ä¸­ç­‰æ˜¾å­˜
        export EXPERIENCE_BUFFER_SIZE=5000
        export PROJECTION_DIM=100
        export UPDATE_FREQUENCY=10
        BATCH_SIZE=32
        print_info "ä½¿ç”¨æ ‡å‡†å‚æ•°"
    else
        # å¤§æ˜¾å­˜
        export EXPERIENCE_BUFFER_SIZE=8000
        export PROJECTION_DIM=128
        export UPDATE_FREQUENCY=5
        BATCH_SIZE=64
        print_info "ä½¿ç”¨é«˜æ€§èƒ½å‚æ•°"
    fi
    
    print_success "å‚æ•°ä¼˜åŒ–å®Œæˆ"
}

# åˆ›å»ºè®­ç»ƒé…ç½®
create_training_config() {
    print_info "åˆ›å»ºè®­ç»ƒé…ç½®..."
    
    cat > $EXPERIMENT_DIR/training_config.yaml << EOF
# AutoDL è®­ç»ƒé…ç½®
experiment_name: $EXPERIMENT_NAME
dataset: $DATASET
config_file: $CONFIG
timestamp: $(date)

# ç¡¬ä»¶é…ç½®
gpus: $GPUS
batch_size: $BATCH_SIZE
max_epochs: $MAX_EPOCHS

# Experience Replay é…ç½®
experience_replay:
  buffer_size: ${EXPERIENCE_BUFFER_SIZE:-5000}
  projection_dim: ${PROJECTION_DIM:-100}
  update_frequency: ${UPDATE_FREQUENCY:-10}
  similarity_threshold: 0.8

# è·¯å¾„é…ç½®
paths:
  data_dir: $DATA_DIR
  checkpoint_dir: $CHECKPOINT_DIR
  result_dir: $RESULT_DIR
  log_dir: $EXPERIMENT_DIR
EOF
    
    print_success "è®­ç»ƒé…ç½®åˆ›å»ºå®Œæˆ"
}

# å¯åŠ¨è®­ç»ƒ
start_training() {
    print_info "å¼€å§‹è®­ç»ƒæ¨¡å‹..."
    
    # åˆ›å»ºè®­ç»ƒå‘½ä»¤
    case $DATASET in
        "mvtec")
            TRAIN_SCRIPT="scripts/train_mvtec.py"
            ;;
        "visa")
            TRAIN_SCRIPT="scripts/train_visa.py"
            ;;
    esac
    
    # æ£€æŸ¥è®­ç»ƒè„šæœ¬æ˜¯å¦å­˜åœ¨
    if [ ! -f "$TRAIN_SCRIPT" ]; then
        print_warning "è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨ï¼Œä½¿ç”¨é€šç”¨è®­ç»ƒæ–¹æ³•"
        TRAIN_SCRIPT="example_experience_replay_usage.py"
    fi
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    TRAIN_CMD="python $TRAIN_SCRIPT"
    
    if [ -f "$CONFIG" ]; then
        TRAIN_CMD="$TRAIN_CMD --config $CONFIG"
    fi
    
    TRAIN_CMD="$TRAIN_CMD --gpus $GPUS --max_epochs $MAX_EPOCHS --batch_size $BATCH_SIZE"
    
    # è®°å½•è®­ç»ƒä¿¡æ¯
    echo "è®­ç»ƒå‘½ä»¤: $TRAIN_CMD" > $EXPERIMENT_DIR/train_command.txt
    echo "å¼€å§‹æ—¶é—´: $(date)" >> $EXPERIMENT_DIR/train_info.txt
    
    print_info "æ‰§è¡Œè®­ç»ƒå‘½ä»¤: $TRAIN_CMD"
    
    # å¯åŠ¨è®­ç»ƒå¹¶è®°å½•æ—¥å¿—
    $TRAIN_CMD 2>&1 | tee $EXPERIMENT_DIR/training.log
    
    # è®°å½•ç»“æŸæ—¶é—´
    echo "ç»“æŸæ—¶é—´: $(date)" >> $EXPERIMENT_DIR/train_info.txt
    
    print_success "è®­ç»ƒå®Œæˆï¼"
}

# è®­ç»ƒåå¤„ç†
post_training() {
    print_info "æ‰§è¡Œè®­ç»ƒåå¤„ç†..."
    
    # ä¿å­˜ç³»ç»Ÿä¿¡æ¯
    nvidia-smi > $EXPERIMENT_DIR/gpu_info.txt
    df -h > $EXPERIMENT_DIR/disk_info.txt
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶
    if [ -d "$CHECKPOINT_DIR" ] && [ "$(ls -A $CHECKPOINT_DIR)" ]; then
        print_success "æ£€æŸ¥ç‚¹æ–‡ä»¶å·²ä¿å­˜åˆ°: $CHECKPOINT_DIR"
        ls -la $CHECKPOINT_DIR
    fi
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœæ–‡ä»¶
    if [ -d "$RESULT_DIR" ] && [ "$(ls -A $RESULT_DIR)" ]; then
        print_success "ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ°: $RESULT_DIR"
        ls -la $RESULT_DIR
    fi
    
    # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
    cat > $EXPERIMENT_DIR/training_report.md << EOF
# è®­ç»ƒæŠ¥å‘Š

## å®éªŒä¿¡æ¯
- å®éªŒåç§°: $EXPERIMENT_NAME
- æ•°æ®é›†: $DATASET
- é…ç½®æ–‡ä»¶: $CONFIG
- å¼€å§‹æ—¶é—´: $(head -1 $EXPERIMENT_DIR/train_info.txt | cut -d: -f2-)
- ç»“æŸæ—¶é—´: $(tail -1 $EXPERIMENT_DIR/train_info.txt | cut -d: -f2-)

## ç¡¬ä»¶é…ç½®
- GPU æ•°é‡: $GPUS
- æ‰¹æ¬¡å¤§å°: $BATCH_SIZE
- æœ€å¤§è½®æ•°: $MAX_EPOCHS

## æ–‡ä»¶è·¯å¾„
- æ—¥å¿—æ–‡ä»¶: $EXPERIMENT_DIR/training.log
- æ£€æŸ¥ç‚¹: $CHECKPOINT_DIR
- ç»“æœ: $RESULT_DIR

## ä¸‹ä¸€æ­¥
1. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—: cat $EXPERIMENT_DIR/training.log
2. è¿è¡Œæµ‹è¯•: bash scripts/test_autodl.sh $DATASET $CHECKPOINT_DIR
3. åˆ†æç»“æœ: python scripts/analyze_results.py $RESULT_DIR
EOF
    
    print_success "è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: $EXPERIMENT_DIR/training_report.md"
}

# é”™è¯¯å¤„ç†
handle_error() {
    print_error "è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"
    echo "é”™è¯¯æ—¶é—´: $(date)" >> $EXPERIMENT_DIR/train_info.txt
    
    # ä¿å­˜é”™è¯¯ä¿¡æ¯
    if [ -f "$EXPERIMENT_DIR/training.log" ]; then
        tail -50 $EXPERIMENT_DIR/training.log > $EXPERIMENT_DIR/error.log
        print_info "é”™è¯¯æ—¥å¿—å·²ä¿å­˜: $EXPERIMENT_DIR/error.log"
    fi
    
    exit 1
}

# ä¸»å‡½æ•°
main() {
    echo "å¼€å§‹è®­ç»ƒæµç¨‹..."
    
    check_environment
    setup_training_env
    setup_training_dirs
    check_dataset
    check_config
    optimize_training_params
    create_training_config
    start_training
    post_training
    
    echo "================================================"
    print_success "ğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼"
    echo ""
    echo "ğŸ“‹ è®­ç»ƒç»“æœ:"
    echo "   - å®éªŒç›®å½•: $EXPERIMENT_DIR"
    echo "   - æ£€æŸ¥ç‚¹: $CHECKPOINT_DIR"
    echo "   - ç»“æœ: $RESULT_DIR"
    echo ""
    echo "ğŸ“Š æŸ¥çœ‹ç»“æœ:"
    echo "   - è®­ç»ƒæ—¥å¿—: cat $EXPERIMENT_DIR/training.log"
    echo "   - è®­ç»ƒæŠ¥å‘Š: cat $EXPERIMENT_DIR/training_report.md"
    echo "   - GPU ä½¿ç”¨: cat $EXPERIMENT_DIR/gpu_info.txt"
}

# è®¾ç½®é”™è¯¯å¤„ç†
trap handle_error ERR

# è¿è¡Œä¸»å‡½æ•°
main "$@"